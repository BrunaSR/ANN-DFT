{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "massive-bruce",
   "metadata": {},
   "source": [
    "# Training Neural Network to Estimate Discrete Fourier Transform\n",
    "\n",
    "This code show how to generate two neural network to estimate real and imaginary part of the discrete Fourier transform of a signal\n",
    "\n",
    "## Imaginary Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training data\n",
    "\n",
    "n_examples = 30000 # Number of examples\n",
    "t = np.linspace(0, 1,100) # Time vector\n",
    "x_data = []\n",
    "\n",
    "for e in range(n_examples):\n",
    "    n_sin = random.randint(1, 10) # Number of sin\n",
    "    signal = 0\n",
    "    for i in range(n_sin):\n",
    "        freq = random.randint(1, 10) # Sinusoid frequency\n",
    "        aux = np.sin(2*np.pi*freq*t)\n",
    "        signal += aux\n",
    "    signal = signal + np.random.randn(100) # Signal with noise\n",
    "    x_data.append(signal)\n",
    "x_data = np.array(x_data)\n",
    "\n",
    "# Label\n",
    "f_hat = np.fft.fft(x_data, n=100)\n",
    "y_data = np.imag(f_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model_imag = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(51, input_shape=(100,)),\n",
    "    tf.keras.layers.Dense(100),\n",
    "])\n",
    "\n",
    "model_imag.compile(\n",
    "    loss=\"mean_squared_error\",\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history_imag = model_imag.fit(x_data, y_data, batch_size=250, epochs=1500, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss model\n",
    "loss = history_imag.history['loss']\n",
    "val_loss = history_imag.history['val_loss']\n",
    "\n",
    "fig_m, ax_m = plt.subplots(figsize=(12,4))\n",
    "ax_m.plot(np.arange(1500), loss, label='Training')\n",
    "ax_m.plot(np.arange(1500), val_loss, label='Validation')\n",
    "ax_m.set(xlabel='epoch', ylabel='loss')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and history training\n",
    "import os.path\n",
    "\n",
    "if os.path.isfile('imag_part.h5') is False:\n",
    "    model.save('imag_part.h5')\n",
    "\n",
    "if os.path.isfile('history_imag_part.npy') is False:\n",
    "    np.save('history_imag_part.npy', history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-daughter",
   "metadata": {},
   "source": [
    "## Real part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training data\n",
    "\n",
    "n_examples = 30000 # Number of examples\n",
    "t = np.linspace(0, 1,100) # Time vector\n",
    "x_data = []\n",
    "\n",
    "for e in range(n_examples):\n",
    "    n_sin = random.randint(1, 10) # Number of sin\n",
    "    signal = 0\n",
    "    for i in range(n_sin):\n",
    "        freq = random.randint(1, 10) # Sinusoid frequency\n",
    "        aux = np.sin(2*np.pi*freq*t)\n",
    "        signal += aux\n",
    "    signal = signal + np.random.randn(100) # Signal with noise\n",
    "    x_data.append(signal)\n",
    "x_data = np.array(x_data)\n",
    "\n",
    "# Label\n",
    "f_hat = np.fft.fft(x_data, n=100)\n",
    "y_data = np.real(f_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model_real = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(51, input_shape=(100,)),\n",
    "    tf.keras.layers.Dense(100),\n",
    "])\n",
    "\n",
    "model_real.compile(\n",
    "    loss=\"mean_squared_error\",\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history_real = model_real.fit(x_data, y_data, batch_size=250, epochs=1500, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and history training\n",
    "import os.path\n",
    "\n",
    "if os.path.isfile('real_part.h5') is False:\n",
    "    model.save('real_part.h5')\n",
    "\n",
    "if os.path.isfile('history_real_part.npy') is False:\n",
    "    np.save('history_real_part.npy', history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
